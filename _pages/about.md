---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Welcome to my homepage! My name is Shan Jia (Ë¥æÂßó). In Mandarin, my name coincidentally mirrors the pronunciation of "Fake Mountain." What's even more interesting is that my research is closely related to "fake things", including the identification and generation of fake images, videos, audio, and newsüòÄ.

I am currently a Software Engineer at YouTube, Google, working on misinformation and synthetic media detection. Before joining Google, I was a Research Scientist and Assistant Lab Director in the [Media Forensic Lab](https://ubmdfl.cse.buffalo.edu/) led by Professor [Siwei Lyu](https://cse.buffalo.edu/~siweilyu/index.html) at the University at Buffalo (UB), State University of New York.

**Research Interests**: Digital Media Forensics, Biometrics, and Computer Vision, etc.

# üîà News 
<div style="max-height:160px; overflow-y:auto; border:1px solid #ccc; padding:10px;">
<ul>
<li><span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2025.07</span> One paper on AI-generated image detection is accepted by <a href="https://sites.google.com/berkeley.edu/apai-iccv2025/">ICCV 2025 Workshop APAI</a>.</li>
<li><span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2025.06</span> Our <a href="https://dl.acm.org/doi/pdf/10.1145/3733102.3733133">paper</a> won the "<strong>Best Student Paper Award</strong>" at IH&MMSec'25. (Try it out on the <a href="https://zinc.cse.buffalo.edu/ubmdfl/deep-o-meter/landing_page">Deepfake-O-Meter "AVSRDD"</a>üòä)</li>
<li><span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2024.12</span> One <a href="https://arxiv.org/pdf/2408.02191">paper</a> on image inpainting localization is accepted by IEEE Transactions on Information Forensics and Security.</li>
<li><span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2024.11</span> Glad to serve as a Technical Program Chair of <a href="https://www.ihmmsec.org/">13th ACM Workshop on Information Hiding and Multimedia Security</a>.</li>
<li><span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2024.10</span> üéâüéâ I‚Äôm starting a new role as a Software Engineer in YouTube at Google!</li>
<li><span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2024.09</span> One <a href="https://arxiv.org/pdf/2406.00985">paper</a> on multi-aspect text-driven image editing is accepted by NeurIPS 2024.</li>
<li><span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2024.07</span> Glad to serve <a href="https://ieeexplore.ieee.org/xpl/conhome/10672516/proceeding">The 20th IEEE AVSS 2024</a> as a Publication Chair.</li>
<li><span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2024.04</span> Glad to be featured on Buffalo News: <a href="https://buffalonews.com/news/local/business/schumer-ub-tout-buffalos-ai-opportunity-as-nations-top-scientist-visits/article_09fa6c48-f11f-11ee-90cc-73d65e6fecf9.html">link</a>.</li>
<li><span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2024.04</span> One <a href="https://openaccess.thecvf.com/content/CVPR2024W/WMF/papers/Jia_Can_ChatGPT_Detect_DeepFakes_A_Study_of_Using_Multimodal_Large_CVPRW_2024_paper.pdf">paper</a> on using ChatGPT-4V for Deepfake face detection is accepted by CVPR2024 Workshop on Media Forensics (<a href="https://github.com/shanface33/GPT4MF_UB">link</a>).</li>
<li><span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2024.03</span> Two papers are accepted by ICME 2024 <strong>Oral</strong>. Congratulations to Soumyya and Yu!</li>
<li><span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2024.02</span> Glad to give a talk on Deepfake video detection, invited by <a href="https://realitydefender.com/">Reality Defender</a>.</li>
<li><span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2024.01</span> I was interviewed by <a href="https://futurumcareers.com/">Futurum Careers, UK</a> together with Prof. Siwei Lyu (<a href="https://futurumcareers.com/Issue-24.pdf">link1</a>, <a href="https://futurumcareers.com/detecting-deepfakes-how-can-we-ensure-that-generative-ai-is-used-for-good">link2</a>).</li>
<li><span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2024.01</span> One <a href="https://openreview.net/pdf?id=Ny150AblPu">paper</a> on uncovering text-image inconsistency is accepted by ICLR 2024 (<a href="https://www.youtube.com/watch?v=FjI-z3kte4U">video</a>).</li>
<li><span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2023.10</span> One <a href="https://openaccess.thecvf.com/content/WACV2024/papers/Ju_Improving_Fairness_in_Deepfake_Detection_WACV_2024_paper.pdf">paper</a> on improving fairness in deepfake detection is accepted by WACV 2024 (<a href="https://github.com/littlejuyan/DF_Fairness"><strong>Code</strong></a>, <a href="https://www.buffalo.edu/ubnow/stories/2024/01/lyu-deepfake-bias.html">news report by UBNow</a>).</li>
<li><span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2023.09</span> One <a href="https://arxiv.org/pdf/2310.03827">paper</a> on audio-visual deepfake detection is accepted by MIT IEEE Undergraduate Research Technology Conference. Congratulations to Sneha Muppalla (a senior high school student)!</li>
<li><span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2023.08</span> One <a href="https://www.sciencedirect.com/science/article/abs/pii/S0924271623002320">paper</a> on street view imagery analysis is accepted by ISPRS Journal of Photogrammetry and Remote Sensing.</li>
<li><span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2023.08</span> üéâüéâ I‚Äôm starting a new position as Assistant Lab Director at <a href="https://ubmdfl.cse.buffalo.edu/">UB Media Forensic Lab (UB MDFL)</a>! </li>
<li><span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2023.08</span> One <a href="https://arxiv.org/pdf/2211.08615">paper</a>  on image forgery detection is accepted by IEEE Transactions on Multimedia.</li>
<li><span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2023.04</span> Two papers are accepted by CVPR2023 Workshop on Media Forensics (WMF). Autosplice dataset has been released (<a href="https://github.com/shanface33/AutoSplice_Dataset">link</a>)!</li>
<li><span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2022.11</span> One <a href="https://pdf.sciencedirectassets.com/271826/1-s2.0-S0924271622X00129/1-s2.0-S0924271622003021/am.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjENj%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIDPfGZpjp9ypeaJS40PVN5UVojBfPMacghBOZyPpGhcjAiBw45g%2F%2FNE7j4B8KvKjJwHZEo%2FltbDtaEok3KQyI4DDdCq7BQjg%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAUaDDA1OTAwMzU0Njg2NSIMS60MOPpYfLCiQ5wFKo8FgM0MftXLmNXSB6E6KgCjOU26FFihWV3Dolc4GJCiqI%2By%2Bz%2F5aDhfaLUM03wvwvKfakXtJbdR76qiT1U%2FL%2BE3sfADTYlH%2B9CJOaS6u9AcSc6Qt4qdj5ReVMg%2B3wjPbPEaFW1oWnAFRnwVVFpFu8Zjsrfct4vB%2FqVUO8TE6c1qTgLFpjtztKUaVJ1yVSP4DndMglBF7yGHH9LId3ecdvDKagfLk2hccur44Qd3jtgawOYnq29JetNUxHAygueVL3cn%2BPwUSi9%2Bao9h%2FB9hgcIbazYUYVOe0%2Fp6oJbBW9oXkgHJaxedO%2Fsl6fQRImApJEuX1bzuk4gXMOxiDX3vwIVEV2GJzN4Taux44g9Tx%2BwH2kM5XUFPShS3wbBbQo5UmnlVAWjPVC0gQYC%2Bzu7aSOtfoGZ5fX%2B%2B9Xwkinxp7iUYOI8BV03t9ijZQWIGpaNCthGeIssypf9kLftfLqzSAwaA24YEnjMmlbnGP5m%2BibqEE9CRBeFntMdwXqEzG4SimL%2BsgUuRrjs8h3zgZoqbBaCE13Cu%2FmxfEkZ9QTJAUMWReqbTwjhgsIPFBUb8wFsiG3Vbe9lYHuN2K7l1tBiLnWovxk3mtlQkjKJUDI4NM87n4Pgp%2FetFgsuHR8KLMFNNH5s%2B8sxJrYTTyVQuSJYZ%2FKNlvsL%2FSfdTroepHkaIgwAvNWhihluqbByZ07tLwPHCegL4Gs%2BGU1peql7s3FweS7RkV3avo1L72NBt9b9JlPLOIeiolV1m67LoFSI4dDYrfEychtNZWbG2eLKN57LUaTxdPtfR3yc87%2FO0xeIQfQHzdhsXo1lMvpCMWBENg8lb5fv0aoyC3kiTBRhGtHedBlFgIN14gCcPmflowGI0zSKGtzC3tMbDBjqyAYci02Av6Ht1b68dD%2Baz7FTwmByHppLJDl4c5L763KTgEYJzXXxALJqRexgSV8MihBQ2eI8ggVxg%2F%2F2%2Byyejd2Iy6D8aoogltp%2Bdx9o9W%2F5Yaog3wg07PwKLPA6Lc3l54uMt5i06c3e0BowCfsVBCsq2Ti%2Fd9JKmVOSN9OQCjFTBeTFR%2B8yxNJp%2BxstZgYrbum7qp%2FAL1%2FiwfVzsExcTBEdb6cauPKgRCUd%2BKFuRSJLyu%2FY%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250712T002953Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY366K57TR%2F20250712%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=19d880be10f1844c3b46e19310aa4bbd4232a5c447b95040f72588511aef7956&hash=fea9f0dd61dd708c42411082d43c4861819d25f696f7d190c1a780a9325ccc69&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0924271622003021&tid=pdf-90710799-85f1-409a-86f0-f04e52ed3393&sid=1b17576a645893414a29e5c-52c7144ad968gxrqa&type=client">paper</a> on street view image inpainting is accepted by ISPRS Journal of Photogrammetry and Remote Sensing (IF: 12.2).</li>
<li><span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2022.06</span> Two papers on Media Forensics are accepted by ICIP 2022.</li>
<li><span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2022.01</span> One <a href="https://www.albany.edu/faculty/mchang2/files/2022_05_ICASSP_De-Contextualization.pdf">paper</a> on Image-text De-contextualization Detection is accepted by ICASSP 2022.</li>
<li><span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2021.12</span> Glad to give a keynote speech on Deepfakes at <a href="https://mfc.nist.gov/workshop">Open Media Forensics Challenge (OpenMFC) 2020-2021 Workshop</a>.</li>
<li><span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2021.10</span> I joined <a href="https://infocamp.ischool.berkeley.edu/">UC Berkeley InforCamp</a> Deepfake Panel as a speaker.</li>
<li><span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2021.06</span> üéâüéâ I defended my Ph.D. dissertation on face spoofing detection and will join UB as a Post-Doctoral Researcher.</li>
<li><span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2020.12</span> üéâüéâ I joined <a href="http://www.lmars.whu.edu.cn/Upload/1608014392.pdf">2020 International Graduate Workshop on GeoInformatics</a>, and won the Excellent Presentation Award (1/11).</li>
</ul>
</div>


# üìù Publications
<div style="max-height: 330px; overflow-y: auto; border: 1px solid #ccc; padding: 10px;">

<div class='paper-box'>
    <div class='paper-box-image'>
      <div>
        <img src='images/tifs25.png' alt="sym" width="100%">
      </div>
    </div>
<div class='paper-box-text' markdown="1">

**[Dense Feature Interaction Network for Image Inpainting Localization]**

 Ye Yao, Tingfeng Han, <u>Shan Jia*</u>, Siwei Lyu

IEEE Transactions on Information Forensics and Security, TIFS'25, [**Paper**](https://arxiv.org/pdf/2408.02191), [**Code**](https://github.com/Boombb/DeFI-Net_Inpainting)
</div>
</div>

<div class='paper-box'>
    <div class='paper-box-image'>
      <div>
        <img src='images/Neurips24.png' alt="sym" width="100%">
      </div>
    </div>
<div class='paper-box-text' markdown="1">

**[ParallelEdits: Efficient Multi-Aspect Text-Driven Image Editing with Attention Grouping]**

 Mingzhen Huang, Jialing Cai, <u>Shan Jia</u>, Vishnu Suresh Lokhande, Siwei Lyu

The Thirty-eighth Annual Conference on Neural Information Processing Systems, NeurIPS'24, [**Paper**](https://proceedings.neurips.cc/paper_files/paper/2024/file/2847043899e1171183ceadf86bdbb280-Paper-Conference.pdf), [**Project**](https://www.mingzhenhuang.com/projects/ParallelEdits.html), [**Code**](https://github.com/Mingzhen-Huang/ParallelEdits)
</div>
</div>

<div class='paper-box'>
    <div class='paper-box-image'>
      <div>
        <img src='images/WMF24.png' alt="sym" width="100%">
      </div>
    </div>
<div class='paper-box-text' markdown="1">

**[Can Chatgpt Detect Deepfakes? A Study of Using Multimodal Large Language Models for Media Forensics]**

<u>Shan Jia</u>, Reilin Lyu, Kangran Zhao, Yize Chen, Zhiyuan Yan, Yan Ju, Chuanbo Hu, Xin Li, Baoyuan Wu, Siwei Lyu

Workshop on Media Forensics, CVPR2024, [**Paper**](https://openaccess.thecvf.com/content/CVPR2024W/WMF/papers/Jia_Can_ChatGPT_Detect_DeepFakes_A_Study_of_Using_Multimodal_Large_CVPRW_2024_paper.pdf), [**Code**](https://github.com/shanface33/GPT4MF_UB)
</div>
</div>

<div class='paper-box'>
    <div class='paper-box-image'>
      <div>
        <img src='images/ICLR_24.png' alt="sym" width="100%">
      </div>
    </div>
<div class='paper-box-text' markdown="1">

**[Exposing Text-Image Inconsistency Using Diffusion Models]**

 Mingzhen Huang, <u>Shan Jia</u>, Zhou Zhou, Yan Ju, Jialing Cai, Siwei Lyu

The Twelfth International Conference on Learning Representations, ICLR'24, [**Paper**](https://openreview.net/pdf?id=Ny150AblPu), [**Code**](https://mingzhenhuang.com/projects/InconsisDet.html), [**Video**](https://www.youtube.com/watch?v=FjI-z3kte4U)
</div>
</div>

<div class='paper-box'>
    <div class='paper-box-image'>
      <div>
        <img src='images/TMM_23.png' alt="sym" width="100%">
      </div>
    </div>
<div class='paper-box-text' markdown="1">

**[GLFF: Global and Local Feature Fusion for AI-synthesized Image Detection]**

Yan Ju, <u>Shan Jia</u>, Jialing Cai, Haiying Guan, Siwei Lyu

IEEE Transactions on Multimedia, TMM'23, [**Paper**](https://ieeexplore.ieee.org/abstract/document/10246417), [**Code**](https://github.com/littlejuyan/GLFF)
</div>
</div>

<div class='paper-box'>
    <div class='paper-box-image'>
      <div>
        <img src='images/AutoS_23.png' alt="sym" width="100%">
      </div>
    </div>
<div class='paper-box-text' markdown="1">
  
**[AutoSplice: A Text-prompt Manipulated Image Dataset for Media Forensics]**

<u>Shan Jia</u>, Mingzhen Huang, Zhou Zhou, Yan Ju, Jialing Cai, Siwei Lyu

Workshop on Media Forensics, CVPR2023, [**Paper**](https://openaccess.thecvf.com/content/CVPR2023W/WMF/papers/Jia_AutoSplice_A_Text-Prompt_Manipulated_Image_Dataset_for_Media_Forensics_CVPRW_2023_paper.pdf), [**Dataset**](https://github.com/shanface33/AutoSplice_Dataset)

</div>
</div>

<div class='paper-box'>
    <div class='paper-box-image'>
      <div>
        <img src='images/ISPRS_23.png' alt="sym" width="100%">
      </div>
    </div>
<div class='paper-box-text' markdown="1">
  
**[UPDExplainer: an Interpretable Transformer-based Framework for Urban Physical Disorder Detection Using Street View Imagery]**

Chuanbo Hu, <u>Shan Jia*</u>, Fan Zhang, Changjiang Xiao, Mindi Ruan, Jacob Thrasher, and Xin Li

ISPRS Journal of Photogrammetry and Remote Sensing, ISPRS-J'23 [**Paper**](https://www.sciencedirect.com/science/article/abs/pii/S0924271622003021)

</div>
</div>

<div class='paper-box'>
    <div class='paper-box-image'>
      <div>
        <img src='images/DFDM_21.png' alt="sym" width="100%">
      </div>
    </div>
<div class='paper-box-text' markdown="1">

**[Model Attribution of Face-swap Deepfake Videos]**

<u>Shan Jia</u>, Xin Li, Siwei Lyu

2022 IEEE International Conference on Image Processing, ICIP'22, [**Paper**](https://arxiv.org/pdf/2202.12951.pdf), [**Code, Dataset**](https://github.com/shanface33/Deepfake_Model_Attribution)

</div>
</div>

<div class='paper-box'>
    <div class='paper-box-image'>
      <div>
        <img src='images/ISPRSJ_22.png' alt="sym" width="100%">
      </div>
    </div>
<div class='paper-box-text' markdown="1">

**[A Saliency-Guided Street View Image Inpainting Framework for Efficient Last-Meters Wayfinding]**

Chuanbo Hu, <u>Shan Jia*</u>, Fan Zhang, Xin Li

ISPRS Journal of Photogrammetry and Remote Sensing, ISPRS-J'22, [**PDF**](https://www.sciencedirect.com/science/article/abs/pii/S0924271623002320), [**Code**](https://github.com/shanface33/saliency_last_way_finding)

</div>
</div>

<div class='paper-box'>
    <div class='paper-box-image'>
      <div>
        <img src='images/FBC_20.png' alt="sym" width="100%">
      </div>
    </div>
<div class='paper-box-text' markdown="1">

**[3D face anti-spoofing with factorized bilinear coding]**

<u>Shan Jia</u>, Xin Li, Chuanbo Hu, Guodong Guo, Zhengquan Xu

IEEE Transactions on Circuits and Systems for Video Technology, TCSVT'20, [**Paper**](https://arxiv.org/pdf/2005.06514.pdf), [**Dataset**](https://github.com/shanface33/Wax_Figure_Face_DB)

</div>
</div>
</div>


# üéì Education
<div align="center" style="font-size:16px; color:#555; margin-bottom:20px;">
‚ú® <em style="color:#0077aa;">I deeply cherish all these universities ‚Äî they‚Äôve shaped who I am today!</em>
</div>

<style>
.education-grid {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
  gap: 20px;
  max-width: 1600px;
  margin: 0 auto;
}

.education-card {
  perspective: 1000px;
  width: 100%;
  aspect-ratio: 5 / 3;
  position: relative;
}

.education-inner {
  position: relative;
  width: 100%;
  height: 100%;
  text-align: center;
  transition: transform 0.8s;
  transform-style: preserve-3d;
}

.education-card:hover .education-inner {
  transform: rotateY(180deg);
}

.education-front,
.education-back {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  backface-visibility: hidden;
  border: 1px solid #ccc;
  border-radius: 6px;
  overflow: hidden;
  box-shadow: 0 2px 5px rgba(0,0,0,0.1);
}

.education-front img {
  width: 100%;
  height: 100%;
  object-fit: cover;
  display: block;
}

.image-source {
  position: absolute;
  bottom: 0;
  left: 0;
  right: 0;
  background: rgba(255, 255, 255, 0.7);
  font-size: 12px;
  text-align: center;
  padding: 2px 4px;
  z-index: 2; 
}

.education-back {
  background-color: #fff;
  color: #333;
  transform: rotateY(180deg);
  display: flex;
  justify-content: center;
  align-items: center;
  padding: 15px;
  box-sizing: border-box;
  font-size: 14px;
  line-height: 1.4;
  text-align: center;
}
</style>

<div class="education-grid">

<div class="education-card">
  <div class="education-inner">
    <div class="education-front">
      <img src="images/wvu.jpeg" alt="WVU">
    </div>
    <div class="education-back">
      2017.10 - 2021.06<br>
      Visiting Ph.D.<br>
      <a href="https://lcsee.statler.wvu.edu/" target="_blank">
        Department of Computer Science and Electrical Engineering<br>
        West Virginia University, USA
      </a>
    </div>
  </div>
  <div class="image-source">
    Image source: <a href="https://wvutoday.wvu.edu/stories/2023/11/17/new-majors-medical-breakthrough-signal-success-for-wvu" target="_blank">link</a>
  </div>
</div>

<div class="education-card">
  <div class="education-inner">
    <div class="education-front">
      <img src="images/whu2.jpg" alt="WHU">
    </div>
    <div class="education-back">
      2014.09 - 2021.06<br>
      MD-PhD<br>
      <a href="http://www.lmars.whu.edu.cn/en" target="_blank">
        State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing<br>
        Wuhan University, China
      </a>
    </div>
  </div>
  <div class="image-source">
    Image source: <a href="https://intlaffairs.hku.hk/programmes/wuhan-university-exchange-programme" target="_blank">link</a>
  </div>
</div>

<div class="education-card">
  <div class="education-inner">
    <div class="education-front">
      <img src="images/whu.jpg" alt="WHU">
    </div>
    <div class="education-back">
      2010.09 - 2014.06<br>
      Bachelor<br>
      <a href="http://eis.whu.edu.cn/indexone.shtml" target="_blank">
        Electronic Information School<br>
        Wuhan University, China
      </a>
    </div>
  </div>
  <div class="image-source">
    Image source: <a href="https://en.wikipedia.org/wiki/Early_buildings_of_Wuhan_University" target="_blank">link</a>
  </div>
</div>

</div>


<div style="display: flex; justify-content: center; align-items: flex-start; gap: 20px; max-width: 1000px; margin: 0 auto; flex-wrap: wrap;">

<div style="flex: 1; min-width: 300px;">
<h2>üñä Services</h2>
<ul>
<li>Conference Reviewer: <em>WACV, NeurIPS, ICCV, CVPR, ECCV, ICME</em></li>
<li>Journal Reviewer: <em>IEEE TIFS, IEEE TMM, IEEE TIP, IEEE TCSVT, IJCV, IEEE TBIOM, PR, ACM TOG</em></li>
</ul>
</div>

<div style="flex: 0 0 250px; text-align: center;">
<script id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=0077aa&w=250&t=m&d=DWq0xRlaIghROAgH6Lr8tmD_XQEZ-bbDoLfqLus2cPc"></script>
</div>

</div>

