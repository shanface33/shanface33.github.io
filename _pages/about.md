---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Welcome to my homepage! My name is Shan Jia (Ë¥æÂßó). In Mandarin, my name coincidentally mirrors the pronunciation of "Fake Mountain." What's even more interesting is that my research is closely related to "fake things", including the identification and generation of fake images, videos, audio, and newsüòÄ.

I am currently a Software Engineer at YouTube, Google, working on misinformation and synthetic media detection. Before joining Google, I was a Research Scientist and Assistant Lab Director in the [Media Forensic Lab](https://ubmdfl.cse.buffalo.edu/) led by Professor [Siwei Lyu](https://cse.buffalo.edu/~siweilyu/index.html) at the University at Buffalo (UB), State University of New York.

**Research Interests**: Digital Media Forensics, Biometrics, and Computer Vision, etc.

# üîà News 
<div style="max-height:300px; overflow-y:auto; border:1px solid #ccc; padding:10px;">
<ul>
<li><span style="background: #d0f0ff; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2025.07</span> One paper on AI-generated image detection is accepted by <a href="https://sites.google.com/berkeley.edu/apai-iccv2025/">ICCV 2025 Workshop APAI</a>.</li>
<li><span style="background: #d0f0ff; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2025.06</span> Our <a href="https://dl.acm.org/doi/pdf/10.1145/3733102.3733133">paper</a> won the "<strong>Best Student Paper Award</strong>" at IH&MMSec'25. (Try it out on the <a href="https://zinc.cse.buffalo.edu/ubmdfl/deep-o-meter/landing_page">Deepfake-O-Meter "AVSRDD"</a>üòä)</li>
<li><span style="background: #d0f0ff; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2024.12</span> One <a href="https://arxiv.org/pdf/2408.02191">paper</a> on image inpainting localization is accepted by IEEE Transactions on Information Forensics and Security.</li>
<li><span style="background: #d0f0ff; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2024.11</span> Glad to serve as a Technical Program Chair of <a href="https://www.ihmmsec.org/">13th ACM Workshop on Information Hiding and Multimedia Security</a>.</li>
<li><span style="background: #d0f0ff; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2024.10</span> üéâüéâ I‚Äôm starting a new role as a Software Engineer in YouTube at Google!</li>
<li><span style="background: #d0f0ff; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2024.09</span> One <a href="https://arxiv.org/pdf/2406.00985">paper</a> on multi-aspect text-driven image editing is accepted by NeurIPS 2024.</li>
<li><span style="background: #d0f0ff; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2024.07</span> Glad to serve <a href="https://ieeexplore.ieee.org/xpl/conhome/10672516/proceeding">The 20th IEEE AVSS 2024</a> as a Publication Chair.</li>
<li><span style="background: #d0f0ff; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2024.04</span> Glad to be featured on Buffalo News: <a href="https://buffalonews.com/news/local/business/schumer-ub-tout-buffalos-ai-opportunity-as-nations-top-scientist-visits/article_09fa6c48-f11f-11ee-90cc-73d65e6fecf9.html">link</a>.</li>
<li><span style="background: #d0f0ff; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2024.04</span> One <a href="https://openaccess.thecvf.com/content/CVPR2024W/WMF/papers/Jia_Can_ChatGPT_Detect_DeepFakes_A_Study_of_Using_Multimodal_Large_CVPRW_2024_paper.pdf">paper</a> on using ChatGPT-4V for Deepfake face detection is accepted by CVPR2024 Workshop on Media Forensics (<a href="https://github.com/shanface33/GPT4MF_UB">link</a>).</li>
<li><span style="background: #d0f0ff; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2024.03</span> Two papers are accepted by ICME 2024 <strong>Oral</strong>. Congratulations to Soumyya and Yu!</li>
<li><span style="background: #d0f0ff; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2024.02</span> Glad to give a talk on Deepfake video detection, invited by <a href="https://realitydefender.com/">Reality Defender</a>.</li>
<li><span style="background: #d0f0ff; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2024.01</span> I was interviewed by <a href="https://futurumcareers.com/">Futurum Careers, UK</a> together with Prof. Siwei Lyu (<a href="https://futurumcareers.com/Issue-24.pdf">link1</a>, <a href="https://futurumcareers.com/detecting-deepfakes-how-can-we-ensure-that-generative-ai-is-used-for-good">link2</a>).</li>
<li><span style="background: #d0f0ff; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2024.01</span> One <a href="https://openreview.net/pdf?id=Ny150AblPu">paper</a> on uncovering text-image inconsistency is accepted by ICLR 2024 (<a href="https://www.youtube.com/watch?v=FjI-z3kte4U">video</a>).</li>
<li><span style="background: #d0f0ff; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2023.10</span> One <a href="https://openaccess.thecvf.com/content/WACV2024/papers/Ju_Improving_Fairness_in_Deepfake_Detection_WACV_2024_paper.pdf">paper</a> on improving fairness in deepfake detection is accepted by WACV 2024 (<a href="https://github.com/littlejuyan/DF_Fairness"><strong>Code</strong></a>, <a href="https://www.buffalo.edu/ubnow/stories/2024/01/lyu-deepfake-bias.html">news report by UBNow</a>).</li>
<li><span style="background: #d0f0ff; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2023.09</span> One <a href="https://arxiv.org/pdf/2310.03827">paper</a> on audio-visual deepfake detection is accepted by MIT IEEE Undergraduate Research Technology Conference. Congratulations to Sneha Muppalla (a senior high school student)!</li>
<li><span style="background: #d0f0ff; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2023.08</span> One <a href="https://www.sciencedirect.com/science/article/abs/pii/S0924271623002320">paper</a> on street view imagery analysis is accepted by ISPRS Journal of Photogrammetry and Remote Sensing.</li>
<li><span style="background: #d0f0ff; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2023.08</span> üéâüéâ I‚Äôm starting a new position as Assistant Lab Director at <a href="https://ubmdfl.cse.buffalo.edu/">UB Media Forensic Lab (UB MDFL)</a>! </li>
<li><span style="background: #d0f0ff; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2023.08</span> One <a href="https://arxiv.org/pdf/2211.08615">paper</a>  on image forgery detection is accepted by IEEE Transactions on Multimedia.</li>
<li><span style="background: #d0f0ff; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2023.04</span> Two papers are accepted by CVPR2023 Workshop on Media Forensics (WMF). Autosplice dataset has been released (<a href="https://github.com/shanface33/AutoSplice_Dataset">link</a>)!</li>
<li><span style="background: #d0f0ff; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2022.11</span> One <a href="https://pdf.sciencedirectassets.com/271826/1-s2.0-S0924271622X00129/1-s2.0-S0924271622003021/am.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjENj%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIDPfGZpjp9ypeaJS40PVN5UVojBfPMacghBOZyPpGhcjAiBw45g%2F%2FNE7j4B8KvKjJwHZEo%2FltbDtaEok3KQyI4DDdCq7BQjg%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAUaDDA1OTAwMzU0Njg2NSIMS60MOPpYfLCiQ5wFKo8FgM0MftXLmNXSB6E6KgCjOU26FFihWV3Dolc4GJCiqI%2By%2Bz%2F5aDhfaLUM03wvwvKfakXtJbdR76qiT1U%2FL%2BE3sfADTYlH%2B9CJOaS6u9AcSc6Qt4qdj5ReVMg%2B3wjPbPEaFW1oWnAFRnwVVFpFu8Zjsrfct4vB%2FqVUO8TE6c1qTgLFpjtztKUaVJ1yVSP4DndMglBF7yGHH9LId3ecdvDKagfLk2hccur44Qd3jtgawOYnq29JetNUxHAygueVL3cn%2BPwUSi9%2Bao9h%2FB9hgcIbazYUYVOe0%2Fp6oJbBW9oXkgHJaxedO%2Fsl6fQRImApJEuX1bzuk4gXMOxiDX3vwIVEV2GJzN4Taux44g9Tx%2BwH2kM5XUFPShS3wbBbQo5UmnlVAWjPVC0gQYC%2Bzu7aSOtfoGZ5fX%2B%2B9Xwkinxp7iUYOI8BV03t9ijZQWIGpaNCthGeIssypf9kLftfLqzSAwaA24YEnjMmlbnGP5m%2BibqEE9CRBeFntMdwXqEzG4SimL%2BsgUuRrjs8h3zgZoqbBaCE13Cu%2FmxfEkZ9QTJAUMWReqbTwjhgsIPFBUb8wFsiG3Vbe9lYHuN2K7l1tBiLnWovxk3mtlQkjKJUDI4NM87n4Pgp%2FetFgsuHR8KLMFNNH5s%2B8sxJrYTTyVQuSJYZ%2FKNlvsL%2FSfdTroepHkaIgwAvNWhihluqbByZ07tLwPHCegL4Gs%2BGU1peql7s3FweS7RkV3avo1L72NBt9b9JlPLOIeiolV1m67LoFSI4dDYrfEychtNZWbG2eLKN57LUaTxdPtfR3yc87%2FO0xeIQfQHzdhsXo1lMvpCMWBENg8lb5fv0aoyC3kiTBRhGtHedBlFgIN14gCcPmflowGI0zSKGtzC3tMbDBjqyAYci02Av6Ht1b68dD%2Baz7FTwmByHppLJDl4c5L763KTgEYJzXXxALJqRexgSV8MihBQ2eI8ggVxg%2F%2F2%2Byyejd2Iy6D8aoogltp%2Bdx9o9W%2F5Yaog3wg07PwKLPA6Lc3l54uMt5i06c3e0BowCfsVBCsq2Ti%2Fd9JKmVOSN9OQCjFTBeTFR%2B8yxNJp%2BxstZgYrbum7qp%2FAL1%2FiwfVzsExcTBEdb6cauPKgRCUd%2BKFuRSJLyu%2FY%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250712T002953Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY366K57TR%2F20250712%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=19d880be10f1844c3b46e19310aa4bbd4232a5c447b95040f72588511aef7956&hash=fea9f0dd61dd708c42411082d43c4861819d25f696f7d190c1a780a9325ccc69&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0924271622003021&tid=pdf-90710799-85f1-409a-86f0-f04e52ed3393&sid=1b17576a645893414a29e5c-52c7144ad968gxrqa&type=client">paper</a> on street view image inpainting is accepted by ISPRS Journal of Photogrammetry and Remote Sensing (IF: 12.2).</li>
<li><span style="background: #d0f0ff; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2022.06</span> Two papers on Media Forensics are accepted by ICIP 2022.</li>
<li><span style="background: #d0f0ff; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2022.01</span> One <a href="https://www.albany.edu/faculty/mchang2/files/2022_05_ICASSP_De-Contextualization.pdf">paper</a> on Image-text De-contextualization Detection is accepted by ICASSP 2022.</li>
<li><span style="background: #d0f0ff; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2021.12</span> Glad to give a keynote speech on Deepfakes at <a href="https://mfc.nist.gov/workshop">Open Media Forensics Challenge (OpenMFC) 2020-2021 Workshop</a>.</li>
<li><span style="background: #d0f0ff; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2021.10</span> I joined <a href="https://infocamp.ischool.berkeley.edu/">UC Berkeley InforCamp</a> Deepfake Panel as a speaker.</li>
<li><span style="background: #d0f0ff; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2021.06</span> üéâüéâ I defended my Ph.D. dissertation on face spoofing detection and will join UB as a Post-Doctoral Researcher.</li>
<li><span style="background: #d0f0ff; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">2020.12</span> üéâüéâ I joined <a href="http://www.lmars.whu.edu.cn/Upload/1608014392.pdf">2020 International Graduate Workshop on GeoInformatics</a>, and won the Excellent Presentation Award (1/11).</li>
</ul>
</div>


# üìù Publications
<div style="max-height: 400px; overflow-y: auto; border: 1px solid #ccc; padding: 10px;">

  <div class='paper-box'>
    <div class='paper-box-image'>
      <div>
        <span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">ICLR2024</span>
        <img src='images/ICLR_24.png' alt="sym" width="100%">
      </div>
    </div>
<div class='paper-box-text' markdown="1">

**[Exposing Text-Image Inconsistency Using Diffusion Models]**

 Mingzhen Huang, <u>Shan Jia</u>, Zhou Zhou, Yan Ju, Jialing Cai, Siwei Lyu

The Twelfth International Conference on Learning Representations, ICLR24, [**Paper**](https://openreview.net/pdf?id=Ny150AblPu), [**Code**](https://mingzhenhuang.com/projects/InconsisDet.html), [**Video**](https://www.youtube.com/watch?v=FjI-z3kte4U)
</div>
</div>

<div class='paper-box'>
    <div class='paper-box-image'>
      <div>
        <span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">TMM23</span>
        <img src='images/TMM_23.png' alt="sym" width="100%">
      </div>
    </div>
<div class='paper-box-text' markdown="1">

**[GLFF: Global and Local Feature Fusion for AI-synthesized Image Detection]**

Yan Ju, <u>Shan Jia</u>, Jialing Cai, Haiying Guan, Siwei Lyu

IEEE Transactions on Multimedia, [**Paper**](https://ieeexplore.ieee.org/abstract/document/10246417), [**Code**](https://github.com/littlejuyan/GLFF)
</div>
</div>

<div class='paper-box'>
    <div class='paper-box-image'>
      <div>
        <span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">WMF@CVPR23</span>
        <img src='images/AutoS_23.png' alt="sym" width="100%">
      </div>
    </div>
<div class='paper-box-text' markdown="1">
  
**[AutoSplice: A Text-prompt Manipulated Image Dataset for Media Forensics]**

<u>Shan Jia</u>, Mingzhen Huang, Zhou Zhou, Yan Ju, Jialing Cai, Siwei Lyu

Workshop on Media Forensics, CVPR2023, [**Paper**](https://openaccess.thecvf.com/content/CVPR2023W/WMF/papers/Jia_AutoSplice_A_Text-Prompt_Manipulated_Image_Dataset_for_Media_Forensics_CVPRW_2023_paper.pdf), [**Dataset**](https://github.com/shanface33/AutoSplice_Dataset)

</div>
</div>

<div class='paper-box'>
    <div class='paper-box-image'>
      <div>
        <span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">ISPRS-J23</span>
        <img src='images/ISPRS_23.png' alt="sym" width="100%">
      </div>
    </div>
<div class='paper-box-text' markdown="1">
  
**[UPDExplainer: an Interpretable Transformer-based Framework for Urban Physical Disorder Detection Using Street View Imagery]**

Chuanbo Hu, <u>Shan Jia*</u>, Fan Zhang, Changjiang Xiao, Mindi Ruan, Jacob Thrasher, and Xin Li

ISPRS Journal of Photogrammetry and Remote Sensing, [**Paper**](https://www.sciencedirect.com/science/article/abs/pii/S0924271622003021)

</div>
</div>

<div class='paper-box'>
    <div class='paper-box-image'>
      <div>
        <span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">ICIP22</span>
        <img src='images/DFDM_21.png' alt="sym" width="100%">
      </div>
    </div>
<div class='paper-box-text' markdown="1">

**[Model Attribution of Face-swap Deepfake Videos]**

<u>Shan Jia</u>, Xin Li, Siwei Lyu

2022 IEEE International Conference on Image Processing, [**Paper**](https://arxiv.org/pdf/2202.12951.pdf), [**Code, Dataset**](https://github.com/shanface33/Deepfake_Model_Attribution)

</div>
</div>

<div class='paper-box'>
    <div class='paper-box-image'>
      <div>
        <span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">ISPRS-J22</span>
        <img src='images/ISPRSJ_22.png' alt="sym" width="100%">
      </div>
    </div>
<div class='paper-box-text' markdown="1">

**[A Saliency-Guided Street View Image Inpainting Framework for Efficient Last-Meters Wayfinding]**

Chuanbo Hu, <u>Shan Jia*</u>, Fan Zhang, Xin Li

ISPRS Journal of Photogrammetry and Remote Sensing, [**PDF**](https://www.sciencedirect.com/science/article/abs/pii/S0924271623002320), [**Code**](https://github.com/shanface33/saliency_last_way_finding)

</div>
</div>

<div class='paper-box'>
    <div class='paper-box-image'>
      <div>
        <span style="background-color: transparent; font-size: 14px; color: #0077aa; font-weight: bold; padding: 3px 8px; border-radius: 50px; font-family: monospace;">TCSVT20</span>
        <img src='images/FBC_20.png' alt="sym" width="100%">
      </div>
    </div>
<div class='paper-box-text' markdown="1">

**[3D face anti-spoofing with factorized bilinear coding]**

<u>Shan Jia</u>, Xin Li, Chuanbo Hu, Guodong Guo, Zhengquan Xu

IEEE Transactions on Circuits and Systems for Video Technology, [**Paper**](https://arxiv.org/pdf/2005.06514.pdf), [**Dataset**](https://github.com/shanface33/Wax_Figure_Face_DB)

</div>
</div>
</div>

# üè´ Education
- Oct. 2017 - Jun. 2021, Visiting Ph.D., Computer Science, [Department of Computer Science and Electrical Engineering, West Virginia University](https://lcsee.statler.wvu.edu/), USA
- Sep. 2014 - Jun. 2021, MD-PhD, Communication and Information Systems, [State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing, Wuhan University](http://www.lmars.whu.edu.cn/en), China
- Sep. 2010 - Jun. 2014, Bachelor, Electrical Engineering, [Electronic Information School, Wuhan University](http://eis.whu.edu.cn/indexone.shtml), China (Recommended to be a graduate student exempt from an admission exam).

# üñä Services
- Conference Reviewer: *WACV, ICCV, CVPR, ECCV, ICME*
- Journal Reviewer: *IEEE TIFS, IEEE TMM, IEEE TIP, IEEE TCSVT, IJCV, IEEE TBIOM, PR, ACM TOG*


<div align="center">
</div>

<div align="center">
<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=250&t=tt&d=DWq0xRlaIghROAgH6Lr8tmD_XQEZ-bbDoLfqLus2cPc"></script>
</div>
